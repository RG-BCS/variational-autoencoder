{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Variational Autoencoder (VAE) for MNIST Anomaly Detection\n",
        "\n",
        "This notebook demonstrates training and evaluation of a VAE model on MNIST data for anomaly detection.  \n",
        "We use reconstruction loss to identify abnormal samples and evaluate the model with ROC, PR curves, and confusion matrix.\n",
        "\n",
        "---\n",
        "\n",
        "### Contents\n",
        "- Setup and imports\n",
        "- Model training\n",
        "- Threshold selection using reconstruction loss\n",
        "- Evaluation and visualization\n",
        "- Conclusion\n"
      ],
      "metadata": {
        "id": "gljEQ_jgeTEi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8buotyGd2v3"
      },
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from model import VAE_MNIST\n",
        "from dataloader_generator import train_dl, val_dl, test_dl\n",
        "from utils import (\n",
        "    train_model, get_recon_losses_per_image_after_training,\n",
        "    show_reconstructions, plot_confusion_matrix, plot_roc_pr\n",
        ")\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters and Setup\n",
        "\n",
        "We set the random seed for reproducibility and define model parameters, training epochs, and loss type.\n"
      ],
      "metadata": {
        "id": "hFSz1z86earx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproducibility and Hyperparameters\n",
        "seed = 15\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "encoding_size = 10\n",
        "input_channel = 1\n",
        "learning_rate = 1e-3\n",
        "LOSS_TYPE = 'bce'\n",
        "num_epochs = 300\n",
        "\n",
        "index_to_name = {0: 'normal', 1: 'abnormal'}\n",
        "name_to_index = {'normal': 0, 'abnormal': 1}\n"
      ],
      "metadata": {
        "id": "QgjTr6k_eeNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the Model, Optimizer, and Scheduler\n",
        "\n",
        "We instantiate the VAE model, define the Adam optimizer, and setup a cosine annealing learning rate scheduler.\n"
      ],
      "metadata": {
        "id": "uzKrZCVIehwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, optimizer and scheduler setup\n",
        "model = VAE_MNIST(input_channel, encoding_size, drop_rate=0.1, multiple=4, skip_connect=False).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n"
      ],
      "metadata": {
        "id": "UAPt-NPaeirR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model\n",
        "\n",
        "We train the model for the specified number of epochs, tracking training and validation losses.\n"
      ],
      "metadata": {
        "id": "o2f2rY1gemQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_loss, val_loss, train_recon_loss, train_kl_loss = train_model(\n",
        "    model, num_epochs, train_dl, val_dl, test_dl, optimizer,\n",
        "    loss_type=LOSS_TYPE, scheduler=scheduler, clip_norm=True, max_norm=100.0\n",
        ")\n"
      ],
      "metadata": {
        "id": "CKeVIaTpeuz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Determine Anomaly Detection Threshold\n",
        "\n",
        "Using the training set reconstruction losses, we calculate a threshold as mean + 2*std deviation.\n",
        "This threshold will be used to classify test images as normal or abnormal.\n"
      ],
      "metadata": {
        "id": "eIsiRU6UexrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = get_recon_losses_per_image_after_training(model, train_dl, LOSS_TYPE)\n",
        "test_losses = get_recon_losses_per_image_after_training(model, test_dl, LOSS_TYPE)\n",
        "THRESHOLD = train_losses.mean() + 2 * train_losses.std()\n",
        "\n",
        "print(f\"Anomaly detection threshold set at: {THRESHOLD:.4f}\")\n"
      ],
      "metadata": {
        "id": "vTnWJK8seyyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Training Loss Components Over Epochs\n"
      ],
      "metadata": {
        "id": "g0oicCTrfJ_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_loss, label='Total Train Loss')\n",
        "plt.plot(val_loss, label='Total Val Loss')\n",
        "plt.plot(train_recon_loss, label='Recon Loss')\n",
        "plt.plot(train_kl_loss, label='KL Loss')\n",
        "plt.title(\"VAE Loss Components Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZjjUXQMofLOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Reconstructions of Abnormal Samples\n",
        "\n",
        "We extract samples labeled as abnormal from the test set and display their reconstructions.\n"
      ],
      "metadata": {
        "id": "gmJovkAzfOUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_fives = []\n",
        "for x, y in test_dl:\n",
        "    r = x[y == 1]\n",
        "    sample_fives.extend(r)\n",
        "sample_fives_tensor = torch.stack(sample_fives)\n",
        "\n",
        "show_reconstructions(model, dataloader=None, sample_input=sample_fives_tensor, num_images=20)\n"
      ],
      "metadata": {
        "id": "av1Vf1nIfSk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix on Test Set\n",
        "\n",
        "Using the threshold, classify test samples and plot the confusion matrix.\n"
      ],
      "metadata": {
        "id": "i-y0ClgyfVay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(\n",
        "    model, test_dl, threshold=THRESHOLD,\n",
        "    labels=['normal', 'abnormal'], normalize=False,\n",
        "    title='Confusion Matrix', loss_type=LOSS_TYPE\n",
        ")\n"
      ],
      "metadata": {
        "id": "retTNFWbfWYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROC and Precision-Recall Curves\n",
        "\n",
        "Evaluate the model performance with ROC and PR curves to understand classification quality.\n"
      ],
      "metadata": {
        "id": "4q8fXCwTfZEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_roc_pr(model, test_dl)\n"
      ],
      "metadata": {
        "id": "VLQflUOlfb56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reconstruction Loss Distribution\n",
        "\n",
        "Plot the distribution of reconstruction losses for train (normal) and test samples with threshold overlay.\n"
      ],
      "metadata": {
        "id": "r-zCCGKdffuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(train_losses, label='Train (normal)', stat='density', kde=True)\n",
        "sns.histplot(test_losses, label='Test', stat='density', kde=True)\n",
        "plt.axvline(THRESHOLD, color='red', linestyle='--', label='Threshold')\n",
        "plt.title(\"Reconstruction Loss Distribution\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "trlgWljJfh2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "- The VAE model is trained to reconstruct normal MNIST digits and detect anomalies based on reconstruction loss.\n",
        "- Thresholding reconstruction loss effectively separates normal and abnormal samples.\n",
        "- Performance evaluation via confusion matrix and ROC/PR curves shows the modelâ€™s anomaly detection capability.\n",
        "- Reconstruction loss distribution illustrates clear separation with the chosen threshold.\n",
        "\n",
        "This pipeline can be extended to other datasets and architectures for anomaly detection tasks.\n"
      ],
      "metadata": {
        "id": "zBugNawfflZ6"
      }
    }
  ]
}